{"meta":{"title":"SchoIsles","subtitle":null,"description":null,"author":"SchoIsles","url":"http://blog.ziruqiren.com"},"pages":[],"posts":[{"title":"kubernetes 业务平滑升级","slug":"kubernetes-app-graceful-update","date":"2018-01-18T02:26:23.000Z","updated":"2018-01-22T02:50:08.000Z","comments":true,"path":"Kubernetes/kubernetes-app-graceful-update/","link":"","permalink":"http://blog.ziruqiren.com/Kubernetes/kubernetes-app-graceful-update/","excerpt":"Kubernetes 提供了 Deployment 来完成对应用的滚动升级，升级过程中，会先创建新版本的 replicaSet，初始复制个数设为 0，按一定比例增加新版本 replicaSet 的复制个数，成功后减小旧版本 replicaSet 的复制个数，此消彼长，直到新版本 replicaSet 的复制个数达到此 Deployment 设定值，旧版本 replicaSet 的复制个数变为0。 Service 通过标签选择器同时选中新旧两个版本 replicaSet 里的 Pod，不断更新其 Endpoint 列表，从而保证向外暴露出的服务总是可用的。 与此同时，如果 Pod 设置了健康检查项，将能够保证 Endpoint 列表的可靠性。通过 readiness 检查来决定是否要将节点从 Endpoint 列表移除或添加，而 liveness 检测会决定是否要重启此容器。 回想一下传统的部署升级方式，最原始的是停止程序后更新代码再启动，优雅一些的则会在更新代码后派生出新的子进程来工作，更高级的还会在程序运行过程中动态更新模块，甚至更换自身二进制文件，有时候还需要预先在 LB 层下线节点，升级完成后再上线。 这几种方式有着共同的目标 尽可能保证服务不中断 提供服务的实例，身份不改变（比如 ip:port） 而在进入云时代，一切都变了。 不再原地重起实例，一个实例的状态只有启动和退出 实例是全新的，尤其是 IP，无论是以注册方式，还是 LB 反向代理方式来提供服务，实例的身份已经发生了变化，必须及时更新 因此引出两个需求： 实例退出时需优雅关闭 LB 层需预先下线节点 一些长连接类型的服务，一般支持在优雅退出的同时，让客户端重连其它节点，比如 Dubbo。另外 Dubbo 是通过注册来实现动态服务发现的，服务之间相互调用是通过内部软负载均衡直连，不需要借助 Kubernetes 来实现。 其它一些服务，web 类型，自身只实现了优雅重启，并未考虑优雅退出，如 Python 的 Gunicorn， PHP 的 php-fpm，还有 uWSGI，在关闭时比较粗暴，不顾未完成的任务，直接关闭子进程。php-fpm 的介绍中虽然说能接收 SIGQUIT 来完成优雅关闭，但实测效果并不理想。","text":"Kubernetes 提供了 Deployment 来完成对应用的滚动升级，升级过程中，会先创建新版本的 replicaSet，初始复制个数设为 0，按一定比例增加新版本 replicaSet 的复制个数，成功后减小旧版本 replicaSet 的复制个数，此消彼长，直到新版本 replicaSet 的复制个数达到此 Deployment 设定值，旧版本 replicaSet 的复制个数变为0。 Service 通过标签选择器同时选中新旧两个版本 replicaSet 里的 Pod，不断更新其 Endpoint 列表，从而保证向外暴露出的服务总是可用的。 与此同时，如果 Pod 设置了健康检查项，将能够保证 Endpoint 列表的可靠性。通过 readiness 检查来决定是否要将节点从 Endpoint 列表移除或添加，而 liveness 检测会决定是否要重启此容器。 回想一下传统的部署升级方式，最原始的是停止程序后更新代码再启动，优雅一些的则会在更新代码后派生出新的子进程来工作，更高级的还会在程序运行过程中动态更新模块，甚至更换自身二进制文件，有时候还需要预先在 LB 层下线节点，升级完成后再上线。 这几种方式有着共同的目标 尽可能保证服务不中断 提供服务的实例，身份不改变（比如 ip:port） 而在进入云时代，一切都变了。 不再原地重起实例，一个实例的状态只有启动和退出 实例是全新的，尤其是 IP，无论是以注册方式，还是 LB 反向代理方式来提供服务，实例的身份已经发生了变化，必须及时更新 因此引出两个需求： 实例退出时需优雅关闭 LB 层需预先下线节点 一些长连接类型的服务，一般支持在优雅退出的同时，让客户端重连其它节点，比如 Dubbo。另外 Dubbo 是通过注册来实现动态服务发现的，服务之间相互调用是通过内部软负载均衡直连，不需要借助 Kubernetes 来实现。 其它一些服务，web 类型，自身只实现了优雅重启，并未考虑优雅退出，如 Python 的 Gunicorn， PHP 的 php-fpm，还有 uWSGI，在关闭时比较粗暴，不顾未完成的任务，直接关闭子进程。php-fpm 的介绍中虽然说能接收 SIGQUIT 来完成优雅关闭，但实测效果并不理想。 而 nginx 在这方面做的很好，它也是通过接收 SIGQUIT 信号来处理，但能保证在关闭过程中停止监听，不再接受新的请求，空闲子进程直接关闭，活动子进程在任务完成后再关闭。 为了演示，下面我们创建一个 Django 项目，编写两个 View，一个快速返回，另一个延迟一段时间再返回代码如下 views.py 123456789101112import timefrom django.views.generic import Viewfrom django.http.response import HttpResponseclass NormalView(View): def get(self, request, *args, **kwargs): return HttpResponse(\"OK\")class SleepView(View): def get(self, request, *args, **kwargs): time.sleep(10) return HttpResponse(\"Sleep finished\") urls.py 123456......urlpatterns = [ url(r'^$', NormalView.as_view()), url(r'^sleep$', SleepView.as_view()),] 这样，我们得到了两个测试链接，当访问 / 时会立即响应，而当访问 /sleep 时会等待 10s 后才返回 无论是用 Django 内置 manager、Gunirorn、或是 uWSGI 来启动 webserver，在客户端使用 curl 请求 /sleep 链接时，使用 Control + C 中断，或是发送 SIGINT、SIGTERM、SIGQUIT 等信号，都会使 webserver 退出的同时，客户端 curl 中断。Gunicorn、uWSGI 只在平滑重启时才会关心旧的子进程是否有活动连接。 而 nginx 在这方面做的很完善，支持收到 SIGQUIT 信号（kill -3）后平滑关闭，在此过程中 master 进程关闭了监听，并向所有子进程发送 SIGQUIT 信号 关闭 idle 状态的连接 等待 active 状态的连接关闭 关闭空闲的子进程 待所有子进程退出后，关闭 master 进程 因此，在容器环境中，nginx 是用来保障容器退出时不中断业务的最佳方案，我们需要更改容器运行脚本，优化退出步骤，截断容器停止信号 SIGTERM，向 nginx 发送 SIGQUIT，10 次检查仍未完全关闭时，再强制杀掉 nginx， 测试 demo 脚本如下 123456789101112131415161718192021222324252627282930313233343536373839#!/bin/bashif [ \"$1\" == \"bash\" ];then exec /bin/bashfiGUNICORN_PID='/tmp/gunicorn.pid'graceful_exit() &#123; echo \"graceful stop nginx\" nginx -s quit for ((i=10;i--;i&gt;=0)) &#123; pkill -0 nginx if [ $? -ne 0 ];then break else echo \"Check nginx master is graceful exited. The number of remaining retries: $i\" sleep 1 fi if [ $i -eq 1 ];then echo \"kill nginx master\" pkill -9 nginx fi &#125; echo \"kill gunicorn\" kill -2 `cat $GUNICORN_PID` exit&#125;trap 'echo \"receive SIGINT\";graceful_exit;exit' SIGINT SIGTERMnginx -t &amp;&amp; nginxgunicorn p0.wsgi --daemon -b 127.0.0.1:8000 --pid $GUNICORN_PID --max-requests=5000 --workers=4 --log-file - --access-logfile - --error-logfile -mkfifo /tmp/blockexec 3&lt;&gt; /tmp/blockread s &lt;&amp;3 这样一来，发起一个请求 curl &lt;ip:port&gt;/sleep 后， 向容器发送 docker stop 指令，新的请求会失败，报 Connection refused，已发起的请求在 10s 内成功返回后，nginx 停掉了最后一个 worker，关闭主进程，容器退出。demo 里没有去管 Gunicorn 的关闭，而是让操作系统自行处理，生产环境中应该考虑的更严谨一些。 在完成了容器的优雅退出后，还要考虑另外一个问题，如果用了 ipvs 实现 L4 LB，在容器内服务关闭端口监听后，如果 Service 层未及时通知 ipvs 将该节点下线，必然会导致一部分请求继续发给此节点，而一般客户端没有做重连，将会直接返回网络失败，假如还配置了 TCP session affine，那某个用户就悲剧了。 因此，在关闭容器前，最好能先从节点列表里清除，而容器启动后，在健康检查确认后再加入列表。 需要知道的是，ipvs 去掉一个后端节点，并不会造成已建立的连接中断，所以，我们可以放心地通知 ipvs 删除此节点，与此同时，我们需要先在 ipvs 层删除此节点后，再真正地通知程序退出。 Service 是逻辑概念，现在已经有一些项目（如 kube-proxy、kube-router，traefik）通过 watch 集群中 Service、Pod、Endpoint 的变化来实现服务的动态发现。在实施过程中，是否能达到完美的平滑升级？ 在 Pod 的生命周期内，有着一系列的事件（event）发生，如创建、更新、删除，但这些事件具体发生在哪个时间点呢？比如： Pod 创建，是发生在创建前还是创建成功后，readiness 在何时检测成功将其加入 Endpoint 列表？ Pod 删除，是发生在删除指令发出后，还是 Pod 已经被删除，是否会跳过 readiness 直接将其移出 Endpoint 列表？ 因此，在实际环境中使用前需要确认这些问题 Pod 生成时，发出了哪些事件，状态变化经历了哪些阶段，健康检查何时发生，Endpoint 何时添加 Pod 销毁时，发出了哪些事件，是否保证了停止过程中不会有新的请求过来，Endpoint 移除是健康检查的结果还是 Pod 销毁事件直接触发的 readiness检测成功后，Pod 状态发生了怎样的变化，Endpoint 的更新发生在什么时候，kube-dns的缓存如何更新？","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://blog.ziruqiren.com/categories/Kubernetes/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://blog.ziruqiren.com/tags/Kubernetes/"}]},{"title":"toa内核模块","slug":"toa-kernel-module","date":"2017-07-23T12:19:28.000Z","updated":"2018-01-25T06:04:34.000Z","comments":true,"path":"lvs/toa-kernel-module/","link":"","permalink":"http://blog.ziruqiren.com/lvs/toa-kernel-module/","excerpt":"安装测试环境 centos 7.3 内核版本 3.10.0-514 安装编译环境 1yum install bc xmlto asciidoc hmaccalc python-devel newt-devel pesignzlib-devel audit-libs-devel numactl-devel pciutils-devel ncurses-devel pesign elfutils-devel binutils-devel perl-ExtUtils-Embed rpm-build 编译内核模块准备内核源码创建builder用户useradd builder 下载并安装当前内核版本的src包以及devel包 123456wget http://vault.centos.org/7.3.1611/os/x86_64/Packages/kernel-devel-3.10.0-514.el7.x86_64.rpmrpm -ivh kernel-devel-3.10.0-514.el7.x86_64.rpm su - builderwget http://vault.centos.org/7.3.1611/updates/Source/SPackages/kernel-3.10.0-514.2.2.el7.src.rpmrpm -ivh kernel-3.10.0-514.2.2.el7.src.rpm 在builder家目录下产生了rpmbuild目录 释放内核源码到rpmbuild/BUILD目录 123rpmbuild -bp rpmbuild/SPECS/kernel.specls ~/rpmbuild/BUILD/kernel-3.10.0-514.2.2.el7/ 打补丁在taobao的toa.patch(1.0.0.0)基础上，去掉ipv6支持，适配centos7内核，见附件","text":"安装测试环境 centos 7.3 内核版本 3.10.0-514 安装编译环境 1yum install bc xmlto asciidoc hmaccalc python-devel newt-devel pesignzlib-devel audit-libs-devel numactl-devel pciutils-devel ncurses-devel pesign elfutils-devel binutils-devel perl-ExtUtils-Embed rpm-build 编译内核模块准备内核源码创建builder用户useradd builder 下载并安装当前内核版本的src包以及devel包 123456wget http://vault.centos.org/7.3.1611/os/x86_64/Packages/kernel-devel-3.10.0-514.el7.x86_64.rpmrpm -ivh kernel-devel-3.10.0-514.el7.x86_64.rpm su - builderwget http://vault.centos.org/7.3.1611/updates/Source/SPackages/kernel-3.10.0-514.2.2.el7.src.rpmrpm -ivh kernel-3.10.0-514.2.2.el7.src.rpm 在builder家目录下产生了rpmbuild目录 释放内核源码到rpmbuild/BUILD目录 123rpmbuild -bp rpmbuild/SPECS/kernel.specls ~/rpmbuild/BUILD/kernel-3.10.0-514.2.2.el7/ 打补丁在taobao的toa.patch(1.0.0.0)基础上，去掉ipv6支持，适配centos7内核，见附件centos 7.3 toa补丁 添加配置12echo -e '\\n# toa\\nCONFIG_TOA=m' &gt;&gt; .configcp /usr/src/kernels/`uname -r`/Module.symvers . 编译12345make oldconfigmake preparemake modules_prepare make M=net/toa 加载toa模块cp net/toa/toa.ko /tmp 切换到root用户, 加载模块123su - root insmod /tmp/toa.ko 持久化123cp /tmp/toa.ko /lib/modules/`uname -r`/extra/depmod -aecho toa &gt; /etc/modules-load.d/toa.conf reboot参考资料 http://blog.51cto.com/shanks/1393434 http://www.hl10502.com/2017/09/14/centos-build-nbd/ http://blog.csdn.net/wwyyxx26/article/details/6325843 https://github.com/alibaba/ali_kernel_rpm/blob/master/patches.taobao/toa.patch 原理分析fullnat 发给 realserver 的 tcp 包添加了一个 OPTION，用于传递客户端真实地址，real server 通过 toa 模块读取此 OPTION，更改 socket 属性， 使应用层能读取真实的客户端ip端口 toa option数据结构定义1234567struct toa_data&#123; __u8 opcode; __u8 opsize; __u16 port; __u32 ip;&#125; tcpdump抓包后，由wireshark分析，tcp封包细节如图 可以看到，经lvs-fullnat模式封包后, TCP包里新增了一个option， code 为 c8，转十进制后为 200 08 为 size，接下来读取后 6 个字节 前两个字节 c3 f4 为端口号，转码后int(‘0xc3f4’, 16)后为 50164 后4个为ip地址，分别转码后得到 10 211 55 2 于是得到来源客户端为 10.211.55.2:50164 toa模块是如何处理这个option的？当 socket 执行 accept 操作建立连接后，程序可以使用getpeername函数来得到连接对端的 ip 和端口，内核源码里最终是调用了 inet_getname 函数 原本此函数返回的是 L3 层的 source ip，和 L4 层的 source port，但是toa 模块修改了此行为，它从 L4 层取出上游服务写入的tcp option，找到 ip 和 端口，取代了返回结果。 替换 inet_getname 函数首先，toa 定义了一个函数 inet_getname_toa 来替代默认的 inet_getname 函数 1inet_stream_ops_p-&gt;getname = inet_getname_toa; inet_getname_toa函数首先调用默认的inet_getname，得到结果后再做额外的处理 检测socket结构体中sk_user_data是否为空，如果不为空，读取其内容 判断是否为toa option，如果是，解析出ip和端口，替换inet_getname函数的返回结果 sk_user_data（RPC layer private data）又是如何设置的？同样的，toa模块定义了函数tcp_v4_syn_recv_sock_toa，替换了默认的tcp_v4_syn_recv_sock 1ipv4_specific_p-&gt;syn_recv_sock = tcp_v4_syn_recv_sock_toa; 此函数首先调用默认的tcp_v4_syn_recv_sock，得到 socket，遍历tcp options，如果找到toa option(opcode==200)，解析其内容，得到源ip和端口信息，写入此socket结构体的属性sk_user_data中，返回 socket, 然后应用程序通过getpeername方法就能获得此 socket 连接的来源ip和端口了","categories":[{"name":"lvs","slug":"lvs","permalink":"http://blog.ziruqiren.com/categories/lvs/"}],"tags":[]},{"title":"ASCII、Unicode、GBK 和 UTF-8 字符编码的区别联系","slug":"character-difference","date":"2017-05-24T07:07:05.000Z","updated":"2018-01-25T06:04:26.000Z","comments":true,"path":"转载/character-difference/","link":"","permalink":"http://blog.ziruqiren.com/转载/character-difference/","excerpt":"文章转载自 月纷悦ASCII、Unicode、GBK 和 UTF-8 字符编码的区别联系 很久很久以前，有一群人，他们决定用8个可以开合的晶体管来组合成不同的状态，以表示世界上的万物。他们看到8个开关状态是好的，于是他们把这称为”字节“。再后来，他们又做了一些可以处理这些字节的机器，机器开动了，可以用字节来组合出很多状态，状态开始变来变去。他们看到这样是好的，于是它们就这机器称为”计算机“。 ASCII开始计算机只在美国用。八位的字节一共可以组合出256(2的8次方)种不同的状态。 他们把其中的编号从0开始的32种状态分别规定了特殊的用途，一但终端、打印机遇上约定好的这些字节被传过来时，就要做一些约定的动作。遇上0×10, 终端就换行，遇上0×07, 终端就向人们嘟嘟叫，例好遇上0x1b, 打印机就打印反白的字，或者终端就用彩色显示字母。他们看到这样很好，于是就把这些0×20以下的字节状态称为”控制码”。他们又把所有的空 格、标点符号、数字、大小写字母分别用连续的字节状态表示，一直编到了第127号，这样计算机就可以用不同字节来存储英语的文字了。大家看到这样，都感觉 很好，于是大家都把这个方案叫做 ANSI 的”Ascii”编码（American Standard Code for Information Interchange，美国信息互换标准代码）。当时世界上所有的计算机都用同样的ASCII方案来保存英文文字。 后来，就像建造巴比伦塔一样，世界各地的都开始使用计算机，但是很多国家用的不是英文，他们的字母里有许多是ASCII里没有的，为了可以在计算机保存他们的文字，他们决定采用 127号之后的空位来表示这些新的字母、符号，还加入了很多画表格时需要用下到的横线、竖线、交叉等形状，一直把序号编到了最后一个状态255。从128 到255这一页的字符集被称”扩展字符集“。从此之后，贪婪的人类再没有新的状态可以用了，美帝国主义可能没有想到还有第三世界国家的人们也希望可以用到计算机吧！ GB2312等中国人们得到计算机时，已经没有可以利用的字节状态来表示汉字，况且有6000多个常用汉字需要保存呢。但是这难不倒智慧的中国人民，我们不客气地把那些127号之后的奇异符号们直接取消掉, 规定：一个小于127的字符的意义与原来相同，但两个大于127的字符连在一起时，就表示一个汉字，前面的一个字节（他称之为高字节）从0xA1用到 0xF7，后面一个字节（低字节）从0xA1到0xFE，这样我们就可以组合出大约7000多个简体汉字了。在这些编码里，我们还把数学符号、罗马希腊的字母、日文的假名们都编进去了，连在 ASCII 里本来就有的数字、标点、字母都统统重新编了两个字节长的编码，这就是常说的”全角”字符，而原来在127号以下的那些就叫”半角”字符了。 中国人民看到这样很不错，于是就把这种汉字方案叫做 “GB2312“。GB2312 是对 ASCII 的中文扩展。","text":"文章转载自 月纷悦ASCII、Unicode、GBK 和 UTF-8 字符编码的区别联系 很久很久以前，有一群人，他们决定用8个可以开合的晶体管来组合成不同的状态，以表示世界上的万物。他们看到8个开关状态是好的，于是他们把这称为”字节“。再后来，他们又做了一些可以处理这些字节的机器，机器开动了，可以用字节来组合出很多状态，状态开始变来变去。他们看到这样是好的，于是它们就这机器称为”计算机“。 ASCII开始计算机只在美国用。八位的字节一共可以组合出256(2的8次方)种不同的状态。 他们把其中的编号从0开始的32种状态分别规定了特殊的用途，一但终端、打印机遇上约定好的这些字节被传过来时，就要做一些约定的动作。遇上0×10, 终端就换行，遇上0×07, 终端就向人们嘟嘟叫，例好遇上0x1b, 打印机就打印反白的字，或者终端就用彩色显示字母。他们看到这样很好，于是就把这些0×20以下的字节状态称为”控制码”。他们又把所有的空 格、标点符号、数字、大小写字母分别用连续的字节状态表示，一直编到了第127号，这样计算机就可以用不同字节来存储英语的文字了。大家看到这样，都感觉 很好，于是大家都把这个方案叫做 ANSI 的”Ascii”编码（American Standard Code for Information Interchange，美国信息互换标准代码）。当时世界上所有的计算机都用同样的ASCII方案来保存英文文字。 后来，就像建造巴比伦塔一样，世界各地的都开始使用计算机，但是很多国家用的不是英文，他们的字母里有许多是ASCII里没有的，为了可以在计算机保存他们的文字，他们决定采用 127号之后的空位来表示这些新的字母、符号，还加入了很多画表格时需要用下到的横线、竖线、交叉等形状，一直把序号编到了最后一个状态255。从128 到255这一页的字符集被称”扩展字符集“。从此之后，贪婪的人类再没有新的状态可以用了，美帝国主义可能没有想到还有第三世界国家的人们也希望可以用到计算机吧！ GB2312等中国人们得到计算机时，已经没有可以利用的字节状态来表示汉字，况且有6000多个常用汉字需要保存呢。但是这难不倒智慧的中国人民，我们不客气地把那些127号之后的奇异符号们直接取消掉, 规定：一个小于127的字符的意义与原来相同，但两个大于127的字符连在一起时，就表示一个汉字，前面的一个字节（他称之为高字节）从0xA1用到 0xF7，后面一个字节（低字节）从0xA1到0xFE，这样我们就可以组合出大约7000多个简体汉字了。在这些编码里，我们还把数学符号、罗马希腊的字母、日文的假名们都编进去了，连在 ASCII 里本来就有的数字、标点、字母都统统重新编了两个字节长的编码，这就是常说的”全角”字符，而原来在127号以下的那些就叫”半角”字符了。 中国人民看到这样很不错，于是就把这种汉字方案叫做 “GB2312“。GB2312 是对 ASCII 的中文扩展。 但是中国的汉字太多了，我们很快就就发现有许多人的人名没有办法在这里打出来，特别是某些很会麻烦别人的国家领导人。于是我们不得不继续把 GB2312 没有用到的码位找出来老实不客气地用上。 后来还是不够用，于是干脆不再要求低字节一定是127号之后的内码，只要第一个字节是大于127就固定表示这是一个汉字的开始，不管后面跟的是不是扩展字符集里的内容。结果扩展之后的编码方案被称为 GBK 标准，GBK包括了GB2312 的所有内容，同时又增加了近20000个新的汉字（包括繁体字）和符号。 后来少数民族也要用电脑了，于是我们再扩展，又加了几千个新的少数民族的字，GBK扩成了 GB18030。从此之后，中华民族的文化就可以在计算机时代中传承了。 中国的程序员们看到这一系列汉字编码的标准是好的，于是通称他们叫做 “DBCS“（Double Byte Charecter Set 双字节字符集）。在DBCS系列标准里，最大的特点是两字节长的汉字字符和一字节长的英文字符并存于同一套编码方案里，因此他们写的程序为了支持中文处理，必须要注意字串里的每一个字节的值，如果这个值是大于127的，那么就认为一个双字节字符集里的字符出现了。那时候凡是受过加持，会编程的计算机僧侣 们都要每天念下面这个咒语数百遍： “一个汉字算两个英文字符！一个汉字算两个英文字符……” 因为当时各个国家都像中国这样搞出一套自己的编码标准，结果互相之间谁也不懂谁的编码，谁也不支持别人的编码，连大陆和台湾这样只相隔了150海里，使用着同一种语言的兄弟地区，也分别采用了不同的 DBCS 编码方案——当时的中国人想让电脑显示汉字，就必须装上一个”汉字系统”，专门用来处理汉字的显示、输入的问题，但是那个台湾的愚昧封建人士写的算命程序就必须加装另一套支持 BIG5 编码的什么”倚天汉字系统”才可以用，装错了字符系统，显示就会乱了套！这怎么办？而且世界民族之林中还有那些一时用不上电脑的穷苦人民，他们的文字又怎么办？ 真是计算机的巴比伦塔命题啊！ unicode正在这时，大天使加百列及时出现了——一个叫 ISO （国际标谁化组织）的国际组织决定着手解决这个问题。他们采用的方法很简单：废了所有的地区性编码方案，重新搞一个包括了地球上所有文化、所有字母和符号 的编码！他们打算叫它”Universal Multiple-Octet Coded Character Set”，简称 UCS, 俗称 “unicode“。 unicode开始制订时，计算机的存储器容量极大地发展了，空间再也不成为问题了。于是 ISO 就直接规定必须用两个字节，也就是16位来统一表示所有的字符，对于ASCII里的那些“半角”字符，unicode包持其原编码不变，只是将其长度由原来的8位扩展为16位，而其他文化和语言的字符则全部重新统一编码。由于”半角”英文符号只需要用到低8位，所以其高8位永远是0，因此这种大气的方案在保存英文文本时会多浪费一倍的空间。 这时候，从旧社会里走过来的程序员开始发现一个奇怪的现象：他们的strlen函数靠不住了，一个汉字不再是相当于两个字符了，而是一个！是的，从unicode开始，无论是半角的英文字母，还是全角的汉字，它们都是统一的”一个字符“！同时，也都是统一的”两个字节“，请注意”字符”和”字节”两个术语的不同，“字节”是一个8位的物理存贮单元，而“字符”则是一个文化相关的符号。在unicode中，一个字符就是两个字节。一个汉字算两个英文字符的时代已经快过去了。 unicode同样也不完美，这里就有两个的问题，一个是，如何才能区别unicode和ascii？计算机怎么知道三个字节表示一个符号，而不是分别表示三个符号呢？第二个问题是，我们已经知道，英文字母只用一个字节表示就够了，如果unicode统一规定，每个符号用三个或四个字节表示，那么每个英文字母前都必然有二到三个字节是0，这对于存储空间来说是极大的浪费，文本文件的大小会因此大出二三倍，这是难以接受的。 UTF-8unicode在很长一段时间内无法推广，直到互联网的出现，为解决unicode如何在网络上传输的问题，于是面向传输的众多 UTF（UCS Transfer Format）标准出现了，顾名思义，UTF-8就是每次8个位传输数据，而UTF-16就是每次16个位。UTF-8就是在互联网上使用最广的一种unicode的实现方式，这是为传输而设计的编码，并使编码无国界，这样就可以显示全世界上所有文化的字符了。 UTF-8最大的一个特点，就是它是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度，当字符在ASCII码的范围时，就用一个字节表示，保留了ASCII字符一个字节的编码做为它的一部分，注意的是unicode一个中文字符占2个字节，而UTF-8一个中文字符占3个字节）。从unicode到uft-8并不是直接的对应，而是要过一些算法和规则来转换。 Unicode符号范围 UTF-8编码方式 (十六进制) （二进制） 0000 0000-0000 007F 0xxxxxxx 0000 0080-0000 07FF 110xxxxx 10xxxxxx 0000 0800-0000 FFFF 1110xxxx 10xxxxxx 10xxxxxx 0001 0000-0010 FFFF 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx","categories":[{"name":"转载","slug":"转载","permalink":"http://blog.ziruqiren.com/categories/转载/"}],"tags":[]}]}